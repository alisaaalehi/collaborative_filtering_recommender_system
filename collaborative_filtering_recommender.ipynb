{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First draft\n",
    "It is just working!\n",
    "\n",
    "# To Do\n",
    "\n",
    " - clean the code\n",
    " - explain the code step by step\n",
    " - optimize the implementation\n",
    " - add plots\n",
    " - make it work on data format from Kaggle\n",
    " - make it work on any rating data\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"   Collaborative filtering algorithm to predict user ratings for films, based on previous ratings in netflix dataset\n",
    " ---  2018, AliSaaalehi@gmail.com \n",
    " ---  subset of Netflix dataset is used. Look at the \"description.txt\" for more info on dataset\n",
    " \"\"\"\n",
    "\n",
    "import csv\n",
    "import time \n",
    "import math\n",
    "import pdb\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read dataset\n",
    "First thing first! Let's read the dataset. If you look at the \"netflix\" folder, you will find three files there. description.txt explains the dataset. I am summarizing it here:\n",
    "\n",
    "- This dataset is a small subset of the data provided as part of the Netflix Prize.\n",
    "- Each row in the **ratings.txt** file represents a rating of a movie by some user. Its format is:<br>\n",
    "   `MovieID, UserID, Rating` for example: `3740, 1502539, 3.0` <br> Ratings are integers from 1 to 5. \n",
    "- The file **movie_titles.txt** contains information about movies. Its rows have the format:<br>\n",
    "  `MovieID ,YearOfRelease ,Title` for example: `9428,2001,Friend` <br> Note that it contains many more movies than have been mentioned in ratings.txt\n",
    "  \n",
    "  \n",
    "I will create a dictionary called `movie_titles_dict` to store information about movies. Key is movie id and the year and title of the move with together will be values in this dictionary.\n",
    "\n",
    "The numpy array `ratings` contains all the rows of the *ratings.txt*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read movie_titles.txt and store info in a dictionary\n",
    "with open('./netflix/movie_titles.txt', 'r') as file_handle: # , encoding ='ISO-8859-1'\n",
    "    data_reader = csv.reader(file_handle, delimiter=',')\n",
    "    movie_titles_dict = dict()\n",
    "    for row in data_reader:\n",
    "        description = [row[1]] # year of the movie\n",
    "        description.append(row[2]) # append title to this\n",
    "        key = float(row[0]) # key is movie id\n",
    "        movie_titles_dict[key] = description\n",
    "\n",
    "# Read ratings.txt \n",
    "with open('./netflix/ratings.txt', 'r') as file_handle:\n",
    "    data_reader = csv.reader(file_handle, delimiter=',')\n",
    "    ratings = []\n",
    "    for row in data_reader:\n",
    "        ratings.append(list(map(float,row)))\n",
    "# convert it to numpy array\n",
    "ratings=np.asarray(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle the ratings\n",
    "In the **ratings.txt** rows are sorted based on movie ids in the dataset. I'm going to separate the test and train data, so it is better to shuffle them before doing so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the ratings\n",
    "np.random.shuffle(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One important trick!\n",
    "\n",
    "At one point in the code, I want to create a big matrix in which each row corresponds to one user and columns will represent different movies. The values inside the matrix are representing the rates that each user has given to each movie. \n",
    "\n",
    "For example, if the user with id 7 has given the rate 5 for the movie with id 28, the cell in matrix related to user 7 and movie 28 will be filled with 5. Lets call this matrix **users_movies**.\n",
    "\n",
    "I will put zeros in those elements that are not specified.\n",
    "\n",
    "\n",
    "\n",
    "users_movies = <img src=\"./imgs/um.png\">\n",
    "\n",
    "If you look at the all user ids and move ids in the file **ratings.txt** you will notice that we do not have ratings for all users and all the movies. First movie id is 28 and the next available one in the dataset is 48 and the last one is 17137. In case of users, first user id is 7 and the last one is $2649267$. \n",
    "\n",
    "Imagine what would be the size of the matrix if we create the matrix with the number of rows equal to maximum user id which is $2649267$ and the number of rows equal to maximum movie id which is $17137$. So, the matrix would be $2649267 \\times 17137$. This matrix would have $45400488579$ elements! If each element takes one byte in the ram, it will require about 45 Gigabyte just to store this matrix!\n",
    "\n",
    "We can easily make it much smaller, by using just those ids that are present in the dataset, but there is a small problem. Later in the code, we need to refer to the elements inside this matrix, but with the new matrix, we can not do this kind of indexing. For example we can not access it in this way: *a = users_movies[user_id, movie_id]* because for example rates that the user_id 7 has given to movies are stored in the first row of the matrix not in the $user\\_id^{th}$ row of it, so we need a fast way to know that user_id 7 corresponds to the first row of the matrix and as another example, rates related to movie_id 48 are stored in the second column of the matrix.\n",
    "\n",
    "For this purpose, I will create dictionaries to make this correspondence happen easily and quickly.\n",
    "- **users_d** is a dictionary in which the key is user id and the value is row number in the matrix **users_movies** that stores ratings given by this user. For example `users_d[7]` will be 0, and `users_d[79]` is 1.\n",
    "- **movies_d** is a dictionary in which the key is movie id and the value is column number in the matrix **users_movies** that is correspondent to this movie. For example `movies_d[28]` is 0 and `movies_d[17137]` is 91.\n",
    "\n",
    "Let's do the real work:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of users: ', 28968)\n",
      "('First five user ids: ', array([  7.,  79., 199., 481., 769.]))\n",
      "('Last five user ids: ', array([2648853., 2648869., 2648885., 2649120., 2649267.]))\n",
      "('users_d[7]: ', 0)\n",
      "('users_d[2649267]: ', 28966)\n",
      "('Number of movies: ', 92)\n",
      "('First five movie ids: ', array([ 28.,  48., 305., 577., 595.]))\n",
      "('Last five movie ids: ', array([15992., 16082., 16576., 16820., 16933.]))\n",
      "('movies_d[28]: ', 0)\n",
      "('movies_d[2649267]: ', 91)\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary to map user ids to indexes\n",
    "user_unique=np.unique(ratings[:,1])\n",
    "users_num=user_unique.size\n",
    "users_d={x:y for x,y in zip(user_unique,range(users_num))} # user dictionary\n",
    "# print some info\n",
    "print(\"Number of users: \", users_num)\n",
    "print(\"First five user ids: \", user_unique[0:5])\n",
    "print(\"Last five user ids: \", user_unique[-6:-1])\n",
    "print('users_d[7]: ', users_d[7])\n",
    "print('users_d[2649267]: ', users_d[2649267])\n",
    "\n",
    "\n",
    "# create a dictionary to map movie ids to indexes\n",
    "movie_unique=np.unique(ratings[:,0])\n",
    "movies_num=movie_unique.size\n",
    "movies_d={x:y for x,y in zip(movie_unique,range(movies_num))} # movie dictionary\n",
    "# print some info\n",
    "print(\"Number of movies: \", movies_num)\n",
    "print(\"First five movie ids: \", movie_unique[0:5])\n",
    "print(\"Last five movie ids: \", movie_unique[-6:-1])\n",
    "print('movies_d[28]: ', movies_d[28])\n",
    "print('movies_d[2649267]: ', movies_d[17137])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227\n"
     ]
    }
   ],
   "source": [
    "# separate test and train data\n",
    "# be careful, dictionaries should be created before separating test and train!\n",
    "\n",
    "ratings_num=(ratings.shape)[0]\n",
    "#print(ratings_num)\n",
    "\n",
    "test_num= int(math.floor(0.1*ratings_num/100))\n",
    "print(test_num)\n",
    "\n",
    "test_ratings=ratings[0:test_num,:]\n",
    "#print(test_ratings[0:10,:])\n",
    "\n",
    "train_ratings=ratings[test_num+1:-1,:]\n",
    "#print(train_ratings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Shape of the users_movies matrix: ', (28968, 92))\n",
      "('Number of zero element of the matrix: ', 2437512)\n",
      "('Sparsness of the matrix: ', 91.46194301358021)\n"
     ]
    }
   ],
   "source": [
    "# utility functions\n",
    "\n",
    "\n",
    "def show_statistics(users_movies, plot_flag=False, reshape_flag=True):\n",
    "    # this fuction shows some information about the users_movies matrix\n",
    "    \n",
    "    print(\"Shape of the users_movies matrix: \", users_movies.shape)\n",
    "    zero_num=users_movies.size - np.count_nonzero(users_movies)\n",
    "    \n",
    "    print(\"Number of zero element of the matrix: \", zero_num)\n",
    "    print(\"Sparsness of the matrix: \", (float(zero_num) / users_movies.size)*100)\n",
    "\n",
    "    # reshape and plot the matrix like an image\n",
    "    if plot_flag== True:\n",
    "        if reshape_flag==True:\n",
    "            plt.imshow(users_movies.reshape(1632,1633))\n",
    "        else:\n",
    "            plt.imshow(users_movies)\n",
    "        plt.colorbar()\n",
    "        plt.title(\"Reshaped version of user-movie matrix\")\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "# creat users-movies matrix\n",
    "users_movies=np.zeros((users_num,movies_num),dtype=int)\n",
    "\n",
    "for row in train_ratings:\n",
    "    m_index=movies_d[row[0]]\n",
    "    u_index=users_d[row[1]]\n",
    "    users_movies[u_index,m_index]=row[2]\n",
    "\n",
    "show_statistics(users_movies, plot_flag=False, reshape_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of users with zero average ratings: ', 0)\n",
      "[14 24 33 18 20 20 37 20 19]\n",
      "[4 8 9 5 8 6 9 5 6]\n",
      "[3. 3. 3. 3. 2. 3. 4. 4. 3.]\n"
     ]
    }
   ],
   "source": [
    "# mesaure averag\n",
    "\n",
    "users_sum_ratings = np.sum(users_movies, axis=1)\n",
    "nonzero_nums= np.count_nonzero(users_movies, axis=1)\n",
    "users_avg_ratings = np.zeros(users_sum_ratings.shape, dtype=float)\n",
    "\n",
    "# to avoid division by zero\n",
    "#proper_inds = nonzero_nums>0\n",
    "for i in range(users_sum_ratings.size):\n",
    "    if nonzero_nums[i]!=0:\n",
    "        users_avg_ratings[i] = users_sum_ratings[i] / nonzero_nums[i]\n",
    "        \n",
    "print(\"Number of users with zero average ratings: \" , users_avg_ratings.size - np.count_nonzero(users_avg_ratings))\n",
    "s=-10\n",
    "e=-1\n",
    "print(users_sum_ratings[s:e])\n",
    "print(nonzero_nums[s:e])\n",
    "print(users_avg_ratings[s:e])\n",
    "#plt.imshow(users_avg_ratings[0:28900].reshape(170,170))\n",
    "#plt.colorbar()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 4 0 0 0 0 0 0 3 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0\n",
      " 0 0 0 0 0 0 3 5 0 0 0 0 0 4 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Normalize rates by the users average weight\n",
    "\n",
    "print (users_movies[1,:])\n",
    "\n",
    "non_zero_um= np.zeros(users_movies.shape, dtype=int)\n",
    "non_zero_um[users_movies>0]=1\n",
    "\n",
    "users_movies_normalized = np.subtract(users_movies,users_avg_ratings[:,None])\n",
    "users_movies_normalized = np.multiply(users_movies_normalized,non_zero_um)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('processing time: ', 54.82439684867859)\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "# form a matrix containing the number of common movies between users\n",
    "common_matrix=np.matmul(non_zero_um , non_zero_um.T)\n",
    "\n",
    "print(\"processing time: \", time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(user_index, movie_index, min_common_movies=2):\n",
    "     \n",
    "    # Look at the row of the common_matrix which shows number of common movies between this user and all other users in the dataset\n",
    "    # Then filter those that have more than specific number of common movies rated\n",
    "    common_row = common_matrix [user_index,:]\n",
    "    similar_users= (np.where( common_row > min_common_movies))[0] # The function np.Where() returns results in the form of tuple, we need the\n",
    "                                                      #  list of indexes which in in the first lement of that tuple\n",
    "    \n",
    "    active_user_ratings = users_movies_normalized [user_index,:] # Remember these are normalized ratings, we do not need to subtract average to normalize them\n",
    "    \n",
    "    number_of_similar_users = similar_users.size\n",
    "    similarity_list = np.zeros((number_of_similar_users,1), dtype=float) # Empty list to store similarity measures (all w(a,i) from equation (2))\n",
    "    \n",
    "    if (number_of_similar_users == 0):\n",
    "        print ('No smilar user in the dataset found! ')\n",
    "        print ('Averge rating for the user is returned! ')\n",
    "        predicted_rate = users_avg_ratings[user_index]\n",
    "        return predicted_rate\n",
    "    \n",
    "   \n",
    "    for i in range(number_of_similar_users):\n",
    "        current_similar_user_index = similar_users [i]\n",
    "        current_similar_user_ratings = users_movies_normalized [current_similar_user_index,:]\n",
    "\n",
    "        # Numinator of the equation (2): sum of product of active users normalized rating with all similar users\n",
    "        numinator= np.matmul(active_user_ratings.T , current_similar_user_ratings)\n",
    "        \n",
    "        # Denominator part: To avoid foor loops I will using logical operations\n",
    "        number_of_movies = active_user_ratings.size\n",
    "        denuminator_1 = 0\n",
    "        denuminator_2 = 0\n",
    "\n",
    "        for j in range(number_of_movies):\n",
    "            if active_user_ratings[j] !=0 and current_similar_user_ratings[j] !=0:\n",
    "                denuminator_1 += (active_user_ratings[j] **2)\n",
    "                denuminator_2 += (current_similar_user_ratings[j] **2)\n",
    "        denuminator = math.sqrt(denuminator_1 * denuminator_2)\n",
    "\n",
    "        # Avoid division\n",
    "        if denuminator == 0:\n",
    "            similarity_list[i] = 0\n",
    "        else:\n",
    "            similarity_list[i] = numinator / denuminator      \n",
    "        \n",
    "    \n",
    "    # Finally sum up every thing and mesure predicted rate\n",
    "    sigma_part = 0\n",
    "    for i in range(number_of_similar_users):\n",
    "        current_similar_user_index = similar_users [i]\n",
    "        sigma_part = users_movies_normalized [current_similar_user_index, movie_index] * similarity_list[i]\n",
    "    \n",
    "    \n",
    "    normalization_factor = np.sum(np.absolute(similarity_list))\n",
    "    predicted_rate= users_avg_ratings[user_index]\n",
    "    \n",
    "    if normalization_factor !=0:\n",
    "        predicted_rate +=  sigma_part / normalization_factor\n",
    "        \n",
    "    # Finall sanity checks (This will not happen hopefully)\n",
    "    if predicted_rate > 5: \n",
    "        predicted_rate = 5 \n",
    "    elif predicted_rate < 0:\n",
    "        predicted_rate = 0\n",
    "    \n",
    "    return predicted_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "('user r: ', 0, '   Predicted Rate=[3.00001905]')\n",
      "             Real rate= 2.0\n",
      "--------------------------------------------------\n",
      "('user r: ', 1, '   Predicted Rate=[2.]')\n",
      "             Real rate= 3.0\n",
      "--------------------------------------------------\n",
      "('user r: ', 2, '   Predicted Rate=[4.]')\n",
      "             Real rate= 4.0\n",
      "--------------------------------------------------\n",
      "('user r: ', 3, '   Predicted Rate=[4.00005535]')\n",
      "             Real rate= 5.0\n",
      "--------------------------------------------------\n",
      "('user r: ', 4, '   Predicted Rate=[2.]')\n",
      "             Real rate= 4.0\n",
      "('MSE: ', array([1.39998548]))\n"
     ]
    }
   ],
   "source": [
    "error = 0\n",
    "num = 5\n",
    "for r in range(num):\n",
    "\n",
    "    row = test_ratings[r,:]\n",
    "    movie_id = movies_d[row[0]]\n",
    "    test_user_id = users_d[row[1]]\n",
    "    real_rate=row[2]\n",
    "    predicted_rate = predict_rating(test_user_id, movie_id, min_common_movies = 0)\n",
    "    print('--------------------------------------------------')\n",
    "    print('user r: ',r,'   Predicted Rate=' + str(predicted_rate))\n",
    "    print('             Real rate= '+ str(real_rate))\n",
    "    error += (predicted_rate - real_rate) ** 2\n",
    "\n",
    "\n",
    "print ('MSE: ', error / num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a valid user id: 160977\n",
      "Enter the desired year: 2011\n",
      "*** Recommended movies ***\n",
      "*** ------------------ ***\n",
      "press q to exit or anything to try againq\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'q' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-ae7e6b7a631c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'*** ------------------ ***'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'press q to exit or anything to try again'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sys_eval_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltin_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mbuiltin_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mbuiltin_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_getpass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.pyc\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'q' is not defined"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    \n",
    "    quary_user_id = 160977\n",
    "    quary_year= '2004'\n",
    "\n",
    "    quary_user_id =  int(input('Enter a valid user id: '))\n",
    "    quary_year = input ('Enter the desired year: ')\n",
    "\n",
    "    min_rate_threshold = 3\n",
    "    test_user_index = users_d[quary_user_id]\n",
    "    print ('*** Recommended movies ***')\n",
    "    for m in movie_unique:\n",
    "        movie_index = movies_d[m]\n",
    "        #print (movie_titles_dict[m][0])\n",
    "\n",
    "        if  users_movies[test_user_index, movie_index]==0 and movie_titles_dict[m][0] == quary_year:\n",
    "            predicted_rate = predict_rating(test_user_id, movie_id, min_common_movies = 2)\n",
    "            if predicted_rate >= min_rate_threshold:\n",
    "                print(movie_titles_dict[m][1])\n",
    "    print ('*** ------------------ ***')\n",
    "    \n",
    "    if input('press q to exit or anything to try again')=='q':\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "“Empirical analysis of Predictive Algorithms for Collaborative Filtering by John S. Breese et al. 1998”"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
